{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport csv, sqlite3\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBClassifier\nimport xgboost as xgb  # Import the XGBoost library\nfrom sklearn.pipeline import Pipeline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\n\n# Suppress specific warnings or all warnings\nwarnings.filterwarnings('ignore')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# House Pricing Dataset - PIPELINE Excercise\n\n## Remark\n\nThis analysis is redone as for \"House Pricing Dataset\", but encouraging Pipelines and ML project approach given in Aurelion Geron \"...\" book. \n\n\n## Overview\nTitle: House Prices: Advanced Regression Techniques\nSource: Kaggle House Prices Dataset\nGoal: Predict the sale prices of houses based on various features.\nDescription: \nThe dataset contains 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa. This dataset is often used to explore advanced regression techniques, feature engineering, and model evaluation.\n\n## Files\n* train.csv: The training dataset with features and the target variable (SalePrice).\n* test.csv: The test dataset with features only, used for making predictions.\n* data_description.txt: Detailed description of each feature in the dataset.\n* sample_submission.csv: A sample submission file in the correct format.\n\n## Key Features\n\nThe dataset includes numerous features describing the properties. Here is a summary of some key features:\n\n<div style=\"display: flex;\">\n\n<div style=\"flex: 1; padding: 10px;\">\n    \n| Feature            | Description                                                   |\n|--------------------|---------------------------------------------------------------|\n| `Id`               | Unique identifier for each property                           |\n| `MSSubClass`       | The building class                                            |\n| `MSZoning`         | The general zoning classification                             |\n| `LotFrontage`      | Linear feet of street connected to the property               |\n| `LotArea`          | Lot size in square feet                                       |\n| `Street`           | Type of road access to the property                           |\n| `Alley`            | Type of alley access to the property                          |\n| `LotShape`         | General shape of property                                     |\n| `LandContour`      | Flatness of the property                                      |\n| `Utilities`        | Type of utilities available                                   |\n| `LotConfig`        | Lot configuration                                             |\n| `LandSlope`        | Slope of property                                             |\n| `Neighborhood`     | Physical locations within Ames city limits                    |\n| `Condition1`       | Proximity to main road or railroad                            |\n| `Condition2`       | Proximity to main road or railroad (if a second is present)   |\n| `BldgType`         | Type of dwelling                                             |\n| `HouseStyle`       | Style of dwelling                                             |\n| `OverallQual`      | Overall material and finish quality                           |\n| `OverallCond`      | Overall condition rating                                      |\n| `YearBuilt`        | Original construction date                                    |\n| `YearRemodAdd`     | Remodel date                                                  |\n| `RoofStyle`        | Type of roof                                                  |\n| `RoofMatl`         | Roof material                                                 |\n| `Exterior1st`      | Exterior covering on house                                    |\n| `Exterior2nd`      | Exterior covering on house (if more than one material)        |\n| `MasVnrType`       | Masonry veneer type                                           |\n| `MasVnrArea`       | Masonry veneer area in square feet                            |\n| `ExterQual`        | Exterior material quality                                     |\n| `ExterCond`        | Present condition of the material on the exterior             |\n| `Foundation`       | Type of foundation                                            |\n| `BsmtQual`         | Height of the basement                                       |\n| `BsmtCond`         | General condition of the basement                             |\n| `BsmtExposure`     | Walkout or garden level basement walls                        |\n| `BsmtFinType1`     | Quality of basement finished area                             |\n| `BsmtFinSF1`       | Type 1 finished square feet                                   |\n| `BsmtFinType2`     | Quality of second finished area (if present)                  |\n| `BsmtFinSF2`       | Type 2 finished square feet                                   |\n| `BsmtUnfSF`        | Unfinished square feet of basement                            |\n| `TotalBsmtSF`      | Total square feet of basement area                            |\n</div>\n\n<div style=\"flex: 1; padding: 10px;\">\n\n| Feature            | Description                                                   |\n|--------------------|---------------------------------------------------------------|\n| `Heating`          | Type of heating                                               |\n| `HeatingQC`        | Heating quality and condition                                 |\n| `CentralAir`       | Central air conditioning (Y/N)                                |\n| `Electrical`       | Electrical system                                             |\n| `1stFlrSF`         | First-floor square feet                                       |\n| `2ndFlrSF`         | Second-floor square feet                                      |\n| `LowQualFinSF`     | Low-quality finished square feet (all floors)                 |\n| `GrLivArea`        | Above grade (ground) living area square feet                  |\n| `BsmtFullBath`     | Basement full bathrooms                                       |\n| `BsmtHalfBath`     | Basement half bathrooms                                       |\n| `FullBath`         | Full bathrooms above grade                                    |\n| `HalfBath`         | Half baths above grade                                        |\n| `BedroomAbvGr`     | Number of bedrooms above basement level                       |\n| `KitchenAbvGr`     | Number of kitchens                                            |\n| `KitchenQual`      | Kitchen quality                                               |\n| `TotRmsAbvGrd`     | Total rooms above grade (does not include bathrooms)          |\n| `Functional`       | Home functionality rating                                     |\n| `Fireplaces`       | Number of fireplaces                                          |\n| `FireplaceQu`      | Fireplace quality                                             |\n| `GarageType`       | Garage location                                               |\n| `GarageYrBlt`      | Year garage was built                                         |\n| `GarageFinish`     | Interior finish of the garage                                 |\n| `GarageCars`       | Size of garage in car capacity                                |\n| `GarageArea`       | Size of garage in square feet                                 |\n| `GarageQual`       | Garage quality                                                |\n| `GarageCond`       | Garage condition                                              |\n| `PavedDrive`       | Paved driveway (Y/N)                                          |\n| `WoodDeckSF`       | Wood deck area in square feet                                 |\n| `OpenPorchSF`      | Open porch area in square feet                                |\n| `EnclosedPorch`    | Enclosed porch area in square feet                            |\n| `3SsnPorch`        | Three-season porch area in square feet                        |\n| `ScreenPorch`      | Screen porch area in square feet                              |\n| `PoolArea`         | Pool area in square feet                                      |\n| `PoolQC`           | Pool quality                                                  |\n| `Fence`            | Fence quality                                                 |\n| `MiscFeature`      | Miscellaneous feature not covered in other categories         |\n| `MiscVal`          | Value of miscellaneous feature                                |\n| `MoSold`           | Month sold                                                    |\n| `YrSold`           | Year sold                                                     |\n| `SaleType`         | Type of sale                                                  |\n| `SaleCondition`    | Condition of sale                                             |\n| `SalePrice`        | Sale price of the property                                    |\n\n</div>\n    \n</div>\nThis dataset is great for practicing data preprocessing, feature engineering, and building regression models. You can find the dataset and more details on the Kaggle competition page: [House Prices - Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques).\n","metadata":{}},{"cell_type":"markdown","source":"## Get data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import IsolationForest, RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.metrics.pairwise import rbf_kernel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load datasets\n#train_data = pd.read_csv(\"C:/Users/dasgu/Downloads/train.csv\")\n#test_data = pd.read_csv(\"C:/Users/dasgu/Downloads/test.csv\")\nhousing_train = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\nhousing_test = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Take a Quick Look at the Data Structure","metadata":{}},{"cell_type":"code","source":"housing_train.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"housing_train.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Wybieramy kolumny typu object\nobject_columns = housing_train.select_dtypes(include=['object'])\n\n# Iterujemy przez kolumny i liczymy unikalne wartości\nunique_values_count = {col: housing_train[col].nunique() for col in object_columns.columns}\n\n# Wyświetlamy wynik\nfor col, count in unique_values_count.items():\n    print(f\"Column '{col}'has {count} uniqe values.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# extra code – the next 5 lines define the default font sizes\nplt.rc('font', size=14)\nplt.rc('axes', labelsize=14, titlesize=14)\nplt.rc('legend', fontsize=14)\nplt.rc('xtick', labelsize=10)\nplt.rc('ytick', labelsize=10)\n\nhousing_train.hist(bins=50, figsize=(12, 8))\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr_matrix = housing_train.corr(numeric_only=True)\n# Wyświetl macierz korelacji\n#plt.figure(figsize=(24, 16))\n#sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n#plt.title('Macierz korelacji')\n#plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr_matrix[\"SalePrice\"].sort_values(ascending=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pandas.plotting import scatter_matrix\n\n# Wybierz tylko zmienne numeryczne\nnumeric_cols = housing_train.select_dtypes(include=['number'])\n\n# Lista atrybutów, które chcesz uwzględnić\nattributes = [\"SalePrice\", 'GrLivArea', \"GarageArea\", \"TotalBsmtSF\", \"1stFlrSF\", \"FullBath\", \"TotRmsAbvGrd\", \"YearBuilt\", \"YearRemodAdd\"]\n\n# Upewnij się, że wszystkie atrybuty znajdują się w zbiorze danych\nattributes = [attr for attr in attributes if attr in numeric_cols.columns]\n\n# Generuj scatter matrix z wybranymi atrybutami\nscatter_matrix(housing_train[attributes], figsize=(18, 12), alpha=0.7, diagonal='hist')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prepare pipelines and Prepare Data","metadata":{}},{"cell_type":"code","source":"# Adding additional features\nluxury_features = [\"PoolArea\", \"Fireplaces\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\"]\n\ndef add_luxury_addon(df):\n    df['LuxAddon'] = df[luxury_features].apply(\n        lambda row: 1 if any((row > 0) & (~row.isna())) else 0, axis=1\n    )\n    return df\n\nhousing_train = add_luxury_addon(housing_train)\nhousing_test = add_luxury_addon(housing_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define features and target variable\nX_features = [\"OverallQual\", \"GrLivArea\", \"GarageArea\", \"TotalBsmtSF\", \"1stFlrSF\", \n              \"FullBath\", \"TotRmsAbvGrd\", \"YearBuilt\", \"YearRemodAdd\", \"GarageYrBlt\", \n              \"MasVnrArea\", \"BsmtFinSF1\", \"LotFrontage\", \"LuxAddon\", \"HalfBath\", \n              \"KitchenAbvGr\", \"MSZoning\", \"Condition1\", \"BldgType\", \"Electrical\", \n              \"Neighborhood\", \"SaleCondition\", \"ExterQual\", \"BsmtQual\", \n              \"HeatingQC\", \"KitchenQual\", \"Functional\"]\n\ny_target = \"SalePrice\"\n\n# Keep only the specified columns\nhousing_train = housing_train[X_features + [y_target]]\nhousing_test = housing_test[X_features]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a custom transformer for feature engineering\nclass FeatureAdder(BaseEstimator, TransformerMixin):\n    print(f\"FeatureAdder\")\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        # Sprawdź typ i kształt danych\n        print(f\"Type of X: {type(X)}\")\n        print(f\"Shape of X: {X.shape}\")\n\n        X_copy = X.copy()\n        X_copy[\"Area_per_piece\"] = X_copy[\"GrLivArea\"] / (X_copy[\"TotRmsAbvGrd\"] + X_copy[\"FullBath\"] + X_copy[\"HalfBath\"] + X_copy[\"KitchenAbvGr\"])\n        X_copy[\"Rooms_per_bathroom\"] = X_copy[\"TotRmsAbvGrd\"] / (X_copy[\"FullBath\"] + X_copy[\"HalfBath\"])\n        print(f\"Type of X_copy (FeatureAdder return): {type(X_copy)}\")\n        print(f\"Shape of X_copy (FeatureAdder return): {X_copy.shape}\")\n\n        return X_copy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RBFTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        # Upewnij się, że X jest DataFrame\n        if not isinstance(X, pd.DataFrame):\n            raise ValueError(\"Expected X to be a DataFrame\")\n        \n        # Upewnij się, że kolumny są dostępne\n        if 'YearBuilt' not in X.columns or 'GarageArea' not in X.columns:\n            raise KeyError(\"Expected columns 'YearBuilt' and 'GarageArea' are not in the DataFrame.\")\n\n        # Sprawdzenie i przetwarzanie danych\n        ages = X[\"YearBuilt\"].values.reshape(-1, 1)\n        garage_area = X[\"GarageArea\"].values.reshape(-1, 1)\n\n        rbf_year = rbf_kernel(ages, [[1.1]], gamma=10)\n        rbf_area = rbf_kernel(garage_area, [[0.1]], gamma=5)\n\n        rbf_features = pd.DataFrame({\n            'RBF_Kernel_YearBuilt': rbf_year.flatten(),\n            'RBF_Kernel_GarageArea': rbf_area.flatten()\n        }, index=X.index)\n\n        # Łączenie nowych cech z oryginalnym DataFrame\n        df = pd.concat([X, rbf_features], axis=1)\n        print(f\"Type of df (RBFTransformer return): {type(df)}\")\n        print(f\"Shape of df (RBFTransformer return): {df.shape}\")\n\n        return df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a custom transformer for outlier removal\nclass OutlierRemover(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        self.isolation_forest = IsolationForest(random_state=42)\n        self.isolation_forest.fit(X)\n        return self\n\n    def transform(self, X):\n        outlier_mask = self.isolation_forest.predict(X) == 1\n        return X[outlier_mask]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass NaNToNoneTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n       # Sprawdź typ i kształt danych\n        print(f\"Type of X (NaNToNoneTransformer in) {type(X)}\")\n        print(f\"Shape of X (NaNToNoneTransformer in): {X.shape}\")\n\n        # Replace NaN with None using Pandas\n        df = X.where(~pd.isna(X), None)\n        print(f\"(NanToNon return) Type of X: {type(df)}\")\n        print(f\"(NanToNon return) Shape of X: {df.shape}\")\n        return X.where(~pd.isna(X), None)\n\n    def get_feature_names_out(self, input_features=None):\n\n        print(f\"(NanToNon return) Type of X: {type(input_features)}\")\n        print(f\"(NanToNon return) Shape of X: {input_features.shape}\")\n        return input_features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass DebugTransformer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        print(\"Transformed DataFrame:\")\n        print(X.columns)\n        return X","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class NumpyToDataFrameTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, columns):\n        self.columns = columns  # Oczekiwane kolumny\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        # Upewnij się, że X jest numpy.ndarray\n        if not isinstance(X, np.ndarray):\n            raise ValueError(\"Expected input to be a numpy.ndarray\")\n\n        # Konwersja do DataFrame\n        return pd.DataFrame(X, columns=self.columns)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify numeric and categorical columns\nnumeric_cols = housing_train.select_dtypes(include=[np.number]).columns.tolist()\nobject_cols = housing_train.select_dtypes(include=['object']).columns.tolist()\n\n# Define columns for one-hot and ordinal encoding\nonehot_columns = [\"MSZoning\", \"Condition1\", \"BldgType\", \"Electrical\", \"Neighborhood\", \"SaleCondition\"]\nordinal_columns = [\"ExterQual\", \"BsmtQual\", \"HeatingQC\", \"KitchenQual\", \"Functional\"]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create numeric pipeline\nnumeric_pipeline = Pipeline(steps=[\n    ('nan_to_none', NaNToNoneTransformer()),  # Convert NaN to None\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\n# Create ordinal pipeline with SimpleImputer and StandardScaler\nordinal_pipeline = Pipeline(steps=[\n    ('nan_to_none', NaNToNoneTransformer()),  # Convert NaN to None\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OrdinalEncoder()),\n    ('scaler', StandardScaler()),\n])# Konwersja na DataFrame\n\n\n# Create ordinal pipeline with SimpleImputer and StandardScaler\nonehot_pipeline = Pipeline(steps=[\n    ('nan_to_none', NaNToNoneTransformer()),  # Convert NaN to None\n    ('onehot', OneHotEncoder(sparse=False, drop='first')),\n\n])# K\n\n# Combine preprocessing pipelines using ColumnTransformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_pipeline, numeric_cols),\n        ('onehot', onehot_pipeline, onehot_columns),\n        ('ordinal', ordinal_pipeline, ordinal_columns)\n    ],\n    remainder='drop'  # Adjust this as needed\n)\n\n# Update your pipelines\npipeline = Pipeline(steps=[\n    ('feature_adder', FeatureAdder()),\n    #('debug1', DebugTransformer()), \n    ('preprocessor', preprocessor),  # Move preprocessor before RBF transformer\n    #('rbf_transformer', RBFTransformer()), # dosnt work so commented\n    #('debug2', DebugTransformer())\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit the pipeline and transform data\nX_train_filtered = pipeline.fit_transform(housing_train)\n\n# Extract target variable\ny_train = housing_train[y_target].values\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Transform the test data using the pre-fitted pipeline\n#X_test_filtered = pipeline.transform(housing_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert processed data back to a DataFrame (especially useful after transformations like OneHotEncoder)\nhousing_train_processed_df = pd.DataFrame(X_train_filtered, columns=pipeline.named_steps['preprocessor'].get_feature_names_out())\nhousing_train_processed_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## OUTLIERS handling","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\n\n# Wybieranie kolumn numerycznych\nnumeric_cols = housing_train_processed_df.select_dtypes(include=['number']).columns\n\n# Tworzenie modelu IsolationForest\nisolation_forest = IsolationForest(random_state=42)\n\n# Dopasowanie modelu do danych numerycznych i przewidywanie anomalii\noutlier_pred = isolation_forest.fit_predict(housing_train_processed_df[numeric_cols])\n\n# Wyświetlenie wyników\noutliers_count = np.sum(outlier_pred == -1)\nprint(f\"Outliers: {outliers_count}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tworzenie maski logicznej: True dla inliers (1), False dla outliers (-1)\nmask = outlier_pred == 1\n\nhousing_train_processed_cleaned = housing_train_processed_df[mask].reset_index(drop=True)\n\nif isinstance(y_train, pd.Series):\n    y_train_cleaned = y_train[mask].reset_index(drop=True)\nelse:\n    y_train_cleaned = y_train[mask]\n\n# Informacje o liczbie wpisów\nprint(f\"Number of entries before removing outliers: {housing_train_processed_df.shape[0]}\")\nprint(f\"Number of entries after removing outliers: {housing_train_processed_cleaned.shape[0]}\")\n\nprint(f\"Number of entries before removing outliers for y_train: {y_train.shape[0]}\")\nprint(f\"Number of entries after removing outliers for y_train: {len(y_train_cleaned)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# RBF KERNEL ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics.pairwise import rbf_kernel\n\n# Ustalanie wartości dla wieku budynków\nages = np.linspace(housing_train_processed_cleaned[\"num__YearBuilt\"].min(),\n                   housing_train_processed_cleaned[\"num__YearBuilt\"].max(),\n                   1000).reshape(-1, 1)\n\n# Ustalanie wartości gamma\ngamma1 = 10\ngamma2 = 5\n\n# Obliczanie jądra RBF dla różnych wartości gamma\nrbf1 = rbf_kernel(ages, [[1.1]], gamma=gamma1)\nrbf2 = rbf_kernel(ages, [[1.1]], gamma=gamma2)\n\n# Tworzenie wykresu\nfig, ax1 = plt.subplots(figsize=(6, 4))  # Ustalanie rozmiaru wykresu\n\n# Wykres histogramu dla wieku budynków\nax1.set_xlabel(\"Year Built\")\nax1.set_ylabel(\"Number of districts\")\nax1.hist(housing_train_processed_cleaned[\"num__YearBuilt\"], bins=50, alpha=0.5, color='gray', label='Districts Histogram')\n\n# Tworzenie drugiej osi y\nax2 = ax1.twinx()  # Tworzenie współdzielonej osi x\ncolor = \"blue\"\nax2.plot(ages, rbf1, color=color, label=gamma1)\nax2.plot(ages, rbf2, color=color, label=gamma2, linestyle=\"--\")\nax2.tick_params(axis='y', labelcolor=color)\nax2.set_ylabel(\"Age similarity\", color=color)\n\n# Dodawanie legendy\nplt.legend(loc=\"upper left\")\nplt.title(\"RBF Kernel Similarity and Histogram of Year Built\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ustalanie wartości dla wieku budynków\nages = np.linspace(housing_train_processed_cleaned[\"num__GarageArea\"].min(),\n                   housing_train_processed_cleaned[\"num__GarageArea\"].max(),\n                   1000).reshape(-1, 1)\n\n# Ustalanie wartości gamma\ngamma1 = 5\ngamma2 = 3\n\n# Obliczanie jądra RBF dla różnych wartości gamma\nrbf1 = rbf_kernel(ages, [[0.1]], gamma=gamma1)\nrbf2 = rbf_kernel(ages, [[0.1]], gamma=gamma2)\n\n# Tworzenie wykresu\nfig, ax1 = plt.subplots(figsize=(6, 4))  # Ustalanie rozmiaru wykresu\n\n# Wykres histogramu dla wieku budynków\nax1.set_xlabel(\"num__GarageArea\")\nax1.set_ylabel(\"Number of districts\")\nax1.hist(housing_train_processed_cleaned[\"num__GarageArea\"], bins=50, alpha=0.5, color='gray', label='Districts Histogram')\n\n# Tworzenie drugiej osi y\nax2 = ax1.twinx()  # Tworzenie współdzielonej osi x\ncolor = \"blue\"\nax2.plot(ages, rbf1, color=color, label=gamma1)\nax2.plot(ages, rbf2, color=color, label=gamma2, linestyle=\"--\")\nax2.tick_params(axis='y', labelcolor=color)\nax2.set_ylabel(\"Area similarity\", color=color)\n\n# Dodawanie legendy\nplt.legend(loc=\"upper left\")\nplt.title(\"RBF Kernel Similarity and Histogram of GarageArea\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics.pairwise import rbf_kernel\n\nages = housing_train_processed_cleaned[\"num__YearBuilt\"].values.reshape(-1, 1)\narea = housing_train_processed_cleaned[\"num__GarageArea\"].values.reshape(-1, 1)\n\nrbf_values_year = rbf_kernel(ages, [[1.1]], gamma=10)\nrbf_values_area = rbf_kernel(area, [[0.1]], gamma=5)\n\n# Dodawanie nowej zmiennej RBF do DataFrame\nhousing_train_processed_cleaned['RBF_Kernel_YearBuild'] = rbf_values_year\nhousing_train_processed_cleaned['RBF_Kernel_GarageArea'] = rbf_values_area\n\nhousing_train_processed_cleaned.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train model and evaluate","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Model training and evaluation\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(random_state=42),\n    'Support Vector Regressor': SVR(),\n    'XGBoost': XGBRegressor(random_state=42),\n    'ElasticNet': ElasticNet()\n}\n\n# Hyperparameter grid for additional models\nparam_grid_svr = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\nparam_grid_xgb = {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 6, 10]}\nparam_grid_rf = {'n_estimators': [50, 100], 'max_depth': [None, 10, 20]\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = {}  # To store evaluation results\n\nfor model_name, model in models.items():\n    print(f\"Training {model_name}...\")\n    \n    if model_name in ['Random Forest', 'Support Vector Regressor', 'XGBoost']:\n        if model_name == 'Random Forest':\n            param_grid = param_grid_rf\n        elif model_name == 'Support Vector Regressor':\n            param_grid = param_grid_svr\n        elif model_name == 'XGBoost':\n            param_grid = param_grid_xgb\n\n        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n        grid_search.fit(housing_train_processed_cleaned, y_train_cleaned)\n        best_model = grid_search.best_estimator_\n        print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n        scores = cross_val_score(best_model, housing_train_processed_cleaned, y_train_cleaned, cv=5, scoring='neg_mean_squared_error')\n    else:\n        scores = cross_val_score(model, housing_train_processed_cleaned, y_train_cleaned, cv=5, scoring='neg_mean_squared_error')\n\n    mean_mse = -np.mean(scores)\n    print(f\"Mean CV MSE for {model_name}: {mean_mse}\")\n    results[model_name] = {'model': model if model_name not in locals() else best_model, 'mse': mean_mse}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import r2_score, mean_squared_error\n\n# Identify the best model based on the lowest MSE\nbest_model_name = min(results, key=lambda x: results[x]['mse'])\nbest_model = results[best_model_name]['model']\n\n# Fit the best model to the training data\nbest_model.fit(housing_train_processed_cleaned, y_train_cleaned)\n\n# Predict on the test set\ny_pred = best_model.predict(housing_train_processed_cleaned)\n\n# Calculate R2 and MSE on the test set\ntest_r2 = r2_score(y_train_cleaned, y_pred)\ntest_mse = mean_squared_error(y_train_cleaned, y_pred)\nprint(f\"Test R2 for {best_model_name}: {test_r2}\")\nprint(f\"Test MSE for {best_model_name}: {test_mse}\")\n\n# Plot residuals (predicted vs true)\nplt.figure(figsize=(10, 6))\nsns.residplot(x=y_pred, y=y_train_cleaned - y_pred, lowess=True, line_kws={'color': 'red', 'lw': 2})\nplt.axhline(0, color='black', linestyle='--', linewidth=1)\nplt.title(f\"Residuals Plot for {best_model_name}\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Residuals\")\nplt.show()\n\n# Predicted vs True plot\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x=y_train_cleaned, y=y_pred, alpha=0.6)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}